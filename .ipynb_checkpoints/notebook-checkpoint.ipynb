{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:38:09.145499Z",
     "iopub.status.busy": "2023-03-05T13:38:09.144791Z",
     "iopub.status.idle": "2023-03-05T13:38:10.136350Z",
     "shell.execute_reply": "2023-03-05T13:38:10.135281Z",
     "shell.execute_reply.started": "2023-03-05T13:38:09.145460Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "#!pip install keras-nlp\n",
    "#from keras_nlp.layers import PositionEmbedding, TransformerEncoder, TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:15:39.719801Z",
     "iopub.status.busy": "2023-03-05T13:15:39.718498Z",
     "iopub.status.idle": "2023-03-05T13:15:40.064097Z",
     "shell.execute_reply": "2023-03-05T13:15:40.062985Z",
     "shell.execute_reply.started": "2023-03-05T13:15:39.719752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Gaeilge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19287</th>\n",
       "      <td>the interpretation and application of the Rule...</td>\n",
       "      <td>léirmhíniú agus cur i bhfeidhm na Rialacha Nós...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11127</th>\n",
       "      <td>Admissible petitions shall be considered by th...</td>\n",
       "      <td>Déanfaidh an coiste freagrach achainíocha ingh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36059</th>\n",
       "      <td>In addition to the provisions of points 10.1 t...</td>\n",
       "      <td>I dteannta fhorálacha phointe 10.1 go pointe 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26256</th>\n",
       "      <td>The President may draw up, for the first part ...</td>\n",
       "      <td>Féadfaidh an tUachtarán liosta cainteoirí a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34185</th>\n",
       "      <td>INTERNAL BUDGETARY PROCEDURES</td>\n",
       "      <td>NÓSANNA IMEACHTA BUISÉADACHA INMHEÁNACHA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "19287  the interpretation and application of the Rule...   \n",
       "11127  Admissible petitions shall be considered by th...   \n",
       "36059  In addition to the provisions of points 10.1 t...   \n",
       "26256  The President may draw up, for the first part ...   \n",
       "34185                      INTERNAL BUDGETARY PROCEDURES   \n",
       "\n",
       "                                                 Gaeilge  \n",
       "19287  léirmhíniú agus cur i bhfeidhm na Rialacha Nós...  \n",
       "11127  Déanfaidh an coiste freagrach achainíocha ingh...  \n",
       "36059  I dteannta fhorálacha phointe 10.1 go pointe 1...  \n",
       "26256  Féadfaidh an tUachtarán liosta cainteoirí a th...  \n",
       "34185           NÓSANNA IMEACHTA BUISÉADACHA INMHEÁNACHA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = pd.read_csv(\"/kaggle/input/bert-nmt/pairs.tsv\", sep='\\t', usecols=[1,3], names=['English', 'Gaeilge'])\n",
    "dcep = pd.read_csv(\"/kaggle/input/dcep-bisentences/EN-GA-bisentences.txt\", sep='\\t', names=['English', 'Gaeilge'])\n",
    "\n",
    "pairs = pd.concat([small, dcep])\n",
    "pairs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:15:40.065968Z",
     "iopub.status.busy": "2023-03-05T13:15:40.065616Z",
     "iopub.status.idle": "2023-03-05T13:15:40.312822Z",
     "shell.execute_reply": "2023-03-05T13:15:40.311728Z",
     "shell.execute_reply.started": "2023-03-05T13:15:40.065933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48806 total pairs\n",
      "39045 training pairs\n",
      "9028 validation pairs\n"
     ]
    }
   ],
   "source": [
    "train = pairs.sample(frac=0.8)\n",
    "val = pairs.drop(train.index)\n",
    "\n",
    "print(f\"{len(pairs)} total pairs\")\n",
    "print(f\"{len(train)} training pairs\")\n",
    "print(f\"{len(val)} validation pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:15:40.317284Z",
     "iopub.status.busy": "2023-03-05T13:15:40.315326Z",
     "iopub.status.idle": "2023-03-05T13:15:50.759555Z",
     "shell.execute_reply": "2023-03-05T13:15:50.758292Z",
     "shell.execute_reply.started": "2023-03-05T13:15:40.317240Z"
    }
   },
   "outputs": [],
   "source": [
    "size = 15000\n",
    "seq_len = 20\n",
    "batch = 64\n",
    "\n",
    "en_vec = layers.TextVectorization(max_tokens=size, output_mode=\"int\", output_sequence_length=seq_len)\n",
    "ga_vec = layers.TextVectorization(max_tokens=size, output_mode=\"int\", output_sequence_length=seq_len+1)\n",
    "\n",
    "en_vec.adapt(pairs[\"English\"])\n",
    "ga_vec.adapt(pairs[\"Gaeilge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:15:50.761329Z",
     "iopub.status.busy": "2023-03-05T13:15:50.760926Z",
     "iopub.status.idle": "2023-03-05T13:15:50.996389Z",
     "shell.execute_reply": "2023-03-05T13:15:50.995377Z",
     "shell.execute_reply.started": "2023-03-05T13:15:50.761289Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_dataset(en, ga):\n",
    "    en = en_vec(en)\n",
    "    ga = ga_vec(ga)\n",
    "    return ({\"encoder_inputs\": en, \"decoder_inputs\": ga[:, :-1],}, ga[:, 1:])\n",
    "\n",
    "def make_dataset(en, ga):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((en, ga))\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "ds = make_dataset(train[\"English\"], train[\"Gaeilge\"])\n",
    "val_ds = make_dataset(val[\"English\"], val[\"Gaeilge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chained-together TransformerEncoder and TransformerDecoder makes up our sequence-to-sequence Transformer. A PositionalEmbedding layer is also used to inform the model of word order.\n",
    "\n",
    "The TransformerEncoder will receive the original sequence and create a new representation. The TransformerDecoder will then receive this modified representation and the current target sequence (target words 0 to N). The TransformerDecoder will next try to anticipate the following words (up to N+1) in the target sequence.\n",
    "\n",
    "Causal masking is a crucial component that enables this (see TransformerDecoder function get causal attention mask() for more information). We must ensure that the TransformerDecoder only takes data from target tokens 0 to N when predicting token N+1 because it sees the full sequences at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:15:50.998764Z",
     "iopub.status.busy": "2023-03-05T13:15:50.998403Z",
     "iopub.status.idle": "2023-03-05T13:15:51.020232Z",
     "shell.execute_reply": "2023-03-05T13:15:51.019087Z",
     "shell.execute_reply.started": "2023-03-05T13:15:50.998726Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:17:32.490524Z",
     "iopub.status.busy": "2023-03-05T13:17:32.489790Z",
     "iopub.status.idle": "2023-03-05T13:17:32.499082Z",
     "shell.execute_reply": "2023-03-05T13:17:32.498008Z",
     "shell.execute_reply.started": "2023-03-05T13:17:32.490486Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 64\n",
    "\n",
    "def create_model(embed_dim, latent_dim, num_heads):\n",
    "    encoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "    pos = PositionalEmbedding(seq_len, size, embed_dim)(encoder_inputs)\n",
    "    encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(pos)\n",
    "    encoder = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "    encoded_seq_inputs = layers.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "    x = PositionalEmbedding(seq_len, size, embed_dim)(decoder_inputs)\n",
    "    x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    decoder_outputs = layers.Dense(size, activation=\"softmax\")(x)\n",
    "    decoder = Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "    transformer = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
    "    \n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T15:13:52.825023Z",
     "iopub.status.busy": "2023-03-04T15:13:52.824618Z",
     "iopub.status.idle": "2023-03-04T16:15:44.248994Z",
     "shell.execute_reply": "2023-03-04T16:15:44.247795Z",
     "shell.execute_reply.started": "2023-03-04T15:13:52.824995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 256)   17878528    ['positional_embedding[0][0]']   \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 15000)  42405784    ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,129,432\n",
      "Trainable params: 64,129,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "611/611 [==============================] - 136s 205ms/step - loss: 4.6578 - accuracy: 0.2419 - val_loss: 3.2496 - val_accuracy: 0.3863\n",
      "Epoch 2/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 2.8961 - accuracy: 0.4399 - val_loss: 2.0746 - val_accuracy: 0.5671\n",
      "Epoch 3/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 1.9382 - accuracy: 0.5967 - val_loss: 1.4482 - val_accuracy: 0.7132\n",
      "Epoch 4/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 1.2566 - accuracy: 0.7343 - val_loss: 0.7961 - val_accuracy: 0.8426\n",
      "Epoch 5/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.8003 - accuracy: 0.8354 - val_loss: 0.5258 - val_accuracy: 0.9091\n",
      "Epoch 6/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.5876 - accuracy: 0.8812 - val_loss: 0.4191 - val_accuracy: 0.9333\n",
      "Epoch 7/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.4617 - accuracy: 0.9071 - val_loss: 0.4181 - val_accuracy: 0.9323\n",
      "Epoch 8/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.3708 - accuracy: 0.9260 - val_loss: 0.3318 - val_accuracy: 0.9536\n",
      "Epoch 9/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.3061 - accuracy: 0.9388 - val_loss: 0.3129 - val_accuracy: 0.9583\n",
      "Epoch 10/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.2614 - accuracy: 0.9480 - val_loss: 0.2973 - val_accuracy: 0.9639\n",
      "Epoch 11/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.2275 - accuracy: 0.9545 - val_loss: 0.2879 - val_accuracy: 0.9656\n",
      "Epoch 12/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.1988 - accuracy: 0.9602 - val_loss: 0.2908 - val_accuracy: 0.9661\n",
      "Epoch 13/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.1787 - accuracy: 0.9639 - val_loss: 0.2786 - val_accuracy: 0.9695\n",
      "Epoch 14/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.1578 - accuracy: 0.9680 - val_loss: 0.2761 - val_accuracy: 0.9701\n",
      "Epoch 15/30\n",
      "611/611 [==============================] - 110s 179ms/step - loss: 0.1453 - accuracy: 0.9703 - val_loss: 0.2741 - val_accuracy: 0.9710\n",
      "Epoch 16/30\n",
      "611/611 [==============================] - 110s 180ms/step - loss: 0.1295 - accuracy: 0.9736 - val_loss: 0.2759 - val_accuracy: 0.9719\n",
      "Epoch 17/30\n",
      "611/611 [==============================] - 110s 179ms/step - loss: 0.1175 - accuracy: 0.9761 - val_loss: 0.2774 - val_accuracy: 0.9717\n",
      "Epoch 18/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.1089 - accuracy: 0.9780 - val_loss: 0.2814 - val_accuracy: 0.9728\n",
      "Epoch 19/30\n",
      "611/611 [==============================] - 110s 179ms/step - loss: 0.1004 - accuracy: 0.9795 - val_loss: 0.2755 - val_accuracy: 0.9727\n",
      "Epoch 20/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0947 - accuracy: 0.9807 - val_loss: 0.2768 - val_accuracy: 0.9727\n",
      "Epoch 21/30\n",
      "611/611 [==============================] - 110s 179ms/step - loss: 0.0883 - accuracy: 0.9822 - val_loss: 0.2818 - val_accuracy: 0.9728\n",
      "Epoch 22/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0832 - accuracy: 0.9831 - val_loss: 0.2828 - val_accuracy: 0.9723\n",
      "Epoch 23/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0773 - accuracy: 0.9844 - val_loss: 0.2862 - val_accuracy: 0.9729\n",
      "Epoch 24/30\n",
      "611/611 [==============================] - 119s 195ms/step - loss: 0.0738 - accuracy: 0.9849 - val_loss: 0.2894 - val_accuracy: 0.9723\n",
      "Epoch 25/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0703 - accuracy: 0.9857 - val_loss: 0.2845 - val_accuracy: 0.9735\n",
      "Epoch 26/30\n",
      "611/611 [==============================] - 110s 180ms/step - loss: 0.0666 - accuracy: 0.9864 - val_loss: 0.2888 - val_accuracy: 0.9742\n",
      "Epoch 27/30\n",
      "611/611 [==============================] - 110s 180ms/step - loss: 0.0632 - accuracy: 0.9872 - val_loss: 0.2817 - val_accuracy: 0.9736\n",
      "Epoch 28/30\n",
      "611/611 [==============================] - 110s 180ms/step - loss: 0.0612 - accuracy: 0.9875 - val_loss: 0.2901 - val_accuracy: 0.9734\n",
      "Epoch 29/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0588 - accuracy: 0.9880 - val_loss: 0.2932 - val_accuracy: 0.9738\n",
      "Epoch 30/30\n",
      "611/611 [==============================] - 109s 179ms/step - loss: 0.0567 - accuracy: 0.9883 - val_loss: 0.2927 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8493807410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30  # This should be at least 30 for convergence\n",
    "\n",
    "transformer = create_model(embed_dim, latent_dim, num_heads)\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T14:37:43.117028Z",
     "iopub.status.busy": "2023-03-05T14:37:43.115964Z",
     "iopub.status.idle": "2023-03-05T14:37:48.377828Z",
     "shell.execute_reply": "2023-03-05T14:37:48.376687Z",
     "shell.execute_reply.started": "2023-03-05T14:37:43.116969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ombudsman may advise the complainant to apply to another authority . \n",
      " -->  an tombudsman a rá leis an ngearánach a chur i gcomhréir leis an údarás eile      \n",
      "\n",
      "Consultation of sensitive documents by the members of the Special Committee of the European Parliament shall take place in a secured room at the Council premises . \n",
      " -->  féachaint ar dhoiciméid íogaire a fháil ón uachtarán pharlaimint na heorpa agus gur cheart fiosrúcháin a ghlacadh sa bhliain ar \n",
      "\n",
      "Simplified procedure \n",
      " -->  procedure                    \n",
      "\n",
      "The Chairs and rapporteurs of the committee responsible and of any associated committees shall jointly take appropriate action to ensure that Parliament is provided with immediate , regular and full information , if necessary on a confidential basis , at all stages of the negotiation and conclusion of international agreements , including the draft and the finally adopted text of negotiating directives , and with the information referred to in paragraph 3 , \n",
      " -->  cathaoirligh agus rapóirtéirí an choiste fhreagraigh agus na gcoistí comhlachaithe i gcás ina comhpháirteach chun a áirithiú go soláthraíonn an \n",
      "\n",
      "The establishment and operation of the register shall respect the rights of Members of the European Parliament to exercise their parliamentary mandate without restriction , and shall not impede access for Members ' constituents to the European Parliament 's premises . \n",
      " -->  parlaimint na heorpa agus an chomhbheartais eachtraigh agus an chláir sin i dtaobh saincheisteanna slándála     más \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ga_vocab = ga_vec.get_vocabulary()\n",
    "ga_index_lookup = dict(zip(range(len(ga_vocab)), ga_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "\n",
    "def decode_sequence(model, input_sentence):\n",
    "    tokenized_input_sentence = en_vec([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = ga_vec([decoded_sentence])[:, :-1]\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = ga_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    try:\n",
    "        inp = \" \".join(nltk.word_tokenize(random.choice(pairs[\"English\"])))\n",
    "        translated = decode_sequence(new_model, inp)\n",
    "        print(inp, \"\\n\", \"--> \", translated[8:], \"\\n\")\n",
    "    except:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-04T16:39:11.967105Z",
     "iopub.status.busy": "2023-03-04T16:39:11.966161Z",
     "iopub.status.idle": "2023-03-04T16:39:13.012855Z",
     "shell.execute_reply": "2023-03-04T16:39:13.011398Z",
     "shell.execute_reply.started": "2023-03-04T16:39:11.967066Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer.save_weights(\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T13:27:21.240182Z",
     "iopub.status.busy": "2023-03-05T13:27:21.239775Z",
     "iopub.status.idle": "2023-03-05T13:27:24.202950Z",
     "shell.execute_reply": "2023-03-05T13:27:24.201896Z",
     "shell.execute_reply.started": "2023-03-05T13:27:21.240143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f84942b07d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = create_model(embed_dim, latent_dim, num_heads)\n",
    "new_model.load_weights(\"/kaggle/input/weights/weights\")\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T14:37:25.421981Z",
     "iopub.status.busy": "2023-03-05T14:37:25.421062Z",
     "iopub.status.idle": "2023-03-05T14:37:26.434368Z",
     "shell.execute_reply": "2023-03-05T14:37:26.433201Z",
     "shell.execute_reply.started": "2023-03-05T14:37:25.421929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parliament decided on the proposal \n",
      " [start] an pharlaimint cinneadh ar an togra               \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = \"The parliament decided on the proposal\"\n",
    "\n",
    "translated = decode_sequence(new_model, inp)\n",
    "print(inp, \"\\n\", translated, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-05T14:35:13.184654Z",
     "iopub.status.busy": "2023-03-05T14:35:13.183962Z",
     "iopub.status.idle": "2023-03-05T14:35:18.180109Z",
     "shell.execute_reply": "2023-03-05T14:35:18.178990Z",
     "shell.execute_reply.started": "2023-03-05T14:35:13.184617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinary Treaty revision \n",
      " gnáth-athbhreithniú ar na conarthaí \n",
      " an tombudsman                   \n",
      " 0 \n",
      "\n",
      "The President shall notify the committee of that initiative and inform Parliament . \n",
      " tabharfaidh an tuachtarán fógra faoin tionscnamh sin don choiste agus cuirfidh sé an pharlaimint ar an eolas faoi . \n",
      " an tuachtarán agus cuirfidh sé an choiste agus an méid sin in iúl don pharlaimint a chur ar an eolas \n",
      " 0.3130668681014416 \n",
      "\n",
      "Committee on Industry , Research and Energy \n",
      " an coiste um thionsclaíocht , um thaighde agus um fhuinneamh \n",
      " coiste um an um thaighde agus um fhuinneamh             \n",
      " 0.5428797663312449 \n",
      "\n",
      "Requests for the application of Rule 50 of the Rules of Procedure shall be submitted no later than the Monday preceding the meeting of the Conference of Committee Chairs at which requests to draw up own-initiative reports are to be dealt with . \n",
      " déanfar iarrataí ar chur i bhfeidhm riail 50 de na rialacha nós imeachta a thíolacadh tráth nach déanaí ná an luan roimh an gcruinniú de chomhdháil chathaoirligh na gcoistí ar lena linn a dhéileálfar le hiarrataí chun tuarascálacha féintionscnaimh a tharraingt suas . \n",
      " iarrataí ar chur i bhfeidhm riail 50 de na rialacha nós imeachta a thíolacadh tráth nach déanaí ná an luan \n",
      " 0.3536031928232399 \n",
      "\n",
      "referral back \n",
      " tarchur ar ais \n",
      " of ais                   \n",
      " 0.14702339453511146 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27131464435820757"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "sample = val.sample(5)\n",
    "bleu = []\n",
    "for en, ga in zip(sample[\"English\"], sample[\"Gaeilge\"]):\n",
    "    en_tk = \" \".join(nltk.word_tokenize(en))\n",
    "    ga_tk = nltk.word_tokenize(ga.lower())\n",
    "    \n",
    "    smoothie = SmoothingFunction().method7\n",
    "    translation = decode_sequence(new_model, en_tk)[8:]\n",
    "    score = sentence_bleu([ga_tk], translation.split(), smoothing_function=smoothie)\n",
    "    \n",
    "    print(en_tk, \"\\n\", \" \".join(ga_tk), \"\\n\", translation, \"\\n\", score, \"\\n\")\n",
    "    bleu.append(score)\n",
    "\n",
    "np.mean(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
