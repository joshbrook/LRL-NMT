{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T13:54:19.445872Z",
     "iopub.execute_input": "2023-05-26T13:54:19.446318Z",
     "iopub.status.idle": "2023-05-26T13:54:36.788720Z",
     "shell.execute_reply.started": "2023-05-26T13:54:19.446288Z",
     "shell.execute_reply": "2023-05-26T13:54:36.787521Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T11:16:24.653901500Z",
     "start_time": "2023-11-23T11:16:15.820986100Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install deep_translator flair contractions language_tool_python\n",
    "\n",
    "import contractions\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "gt = GoogleTranslator(source='en', target='ga')\n",
    "\n",
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "tagger = Classifier.load('pos-fast')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "w2v = api.load('glove-wiki-gigaword-200')\n",
    "\n",
    "import language_tool_python\n",
    "lt = language_tool_python.LanguageTool('en-UK')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T13:54:36.791769Z",
     "iopub.execute_input": "2023-05-26T13:54:36.792744Z",
     "iopub.status.idle": "2023-05-26T13:58:07.699625Z",
     "shell.execute_reply.started": "2023-05-26T13:54:36.792697Z",
     "shell.execute_reply": "2023-05-26T13:58:07.698003Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cgpt = pd.read_csv(\"data/CGPT-corpus.csv\", usecols=[1,2], dtype=str)\n",
    "tatoeba = pd.read_csv(\"data/tatoeba.tsv\", sep='\\t', usecols=[1,3], names=['English', 'Gaeilge'], dtype=str)\n",
    "\n",
    "pairs = pd.concat([cgpt, tatoeba], ignore_index=True)\n",
    "pairs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T13:58:07.701533Z",
     "iopub.execute_input": "2023-05-26T13:58:07.702614Z",
     "iopub.status.idle": "2023-05-26T13:58:07.799856Z",
     "shell.execute_reply.started": "2023-05-26T13:58:07.702554Z",
     "shell.execute_reply": "2023-05-26T13:58:07.798962Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "execution_count": 4,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                English  \\\n0         The papers and the machine are sitting there.   \n1                                  It's cold in winter.   \n2                           I am looking for a new job.   \n3                 That song was on the radio yesterday.   \n4                    The water is coming down the wall.   \n...                                                 ...   \n3383                 She has received a good education.   \n3384                 I'm going to go back to Australia.   \n3385  Tom lives in a small house not far from the ri...   \n3386                                   I won the fight.   \n3387                                  I'm playing golf.   \n\n                                                Gaeilge  \n0               Tá na páipéir agus an mheaisín ina suí.  \n1                         Bíonn sé fuar sa Gheimhreadh.  \n2                               Tá mé ag lorg post nua.  \n3                Bhí an t-amhrán sin ar an raidió inné.  \n4                 Tá an t-uisce ag teacht ar an mballa.  \n...                                                 ...  \n3383                   Tá oideachas maith faighte aici.  \n3384              Táim ag dul ar ais go dtí an Astráil.  \n3385  Tá Tomás ina chónaí i dteach beag nach bhfuil ...  \n3386                               Bhuaigh mé an troid.  \n3387                               Táim ag imirt gailf.  \n\n[3388 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Gaeilge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The papers and the machine are sitting there.</td>\n      <td>Tá na páipéir agus an mheaisín ina suí.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It's cold in winter.</td>\n      <td>Bíonn sé fuar sa Gheimhreadh.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I am looking for a new job.</td>\n      <td>Tá mé ag lorg post nua.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>That song was on the radio yesterday.</td>\n      <td>Bhí an t-amhrán sin ar an raidió inné.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The water is coming down the wall.</td>\n      <td>Tá an t-uisce ag teacht ar an mballa.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3383</th>\n      <td>She has received a good education.</td>\n      <td>Tá oideachas maith faighte aici.</td>\n    </tr>\n    <tr>\n      <th>3384</th>\n      <td>I'm going to go back to Australia.</td>\n      <td>Táim ag dul ar ais go dtí an Astráil.</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>Tom lives in a small house not far from the ri...</td>\n      <td>Tá Tomás ina chónaí i dteach beag nach bhfuil ...</td>\n    </tr>\n    <tr>\n      <th>3386</th>\n      <td>I won the fight.</td>\n      <td>Bhuaigh mé an troid.</td>\n    </tr>\n    <tr>\n      <th>3387</th>\n      <td>I'm playing golf.</td>\n      <td>Táim ag imirt gailf.</td>\n    </tr>\n  </tbody>\n</table>\n<p>3388 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def preproc_en(x):\n",
    "    return \" \".join(nltk.word_tokenize(contractions.fix(str(x).lower())))\n",
    "\n",
    "def preproc_ga(x):\n",
    "    return nltk.word_tokenize(str(x).lower())\n",
    "\n",
    "\n",
    "zipped = list(zip(pairs[\"English\"], pairs[\"Gaeilge\"]))\n",
    "\n",
    "tokens = [[preproc_en(en), preproc_ga(ga)] for en, ga in zipped]\n",
    "\n",
    "tagged = []\n",
    "for en, ga in tokens:\n",
    "    s = Sentence(en)\n",
    "    tagger.predict(s)\n",
    "    tags = [str(list(s)[i]).split()[-2] for i in range(len(en.split()))]\n",
    "    tagged.append([list(zip(en.split(), tags)), ga])\n",
    "    \n",
    "tagged[random.randint(0, len(tagged)-1)]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T13:58:07.804196Z",
     "iopub.execute_input": "2023-05-26T13:58:07.804889Z",
     "iopub.status.idle": "2023-05-26T14:00:52.664596Z",
     "shell.execute_reply.started": "2023-05-26T13:58:07.804842Z",
     "shell.execute_reply": "2023-05-26T14:00:52.663635Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[('okay', 'UH'), ('.', '.')], ['ceart', 'go', 'leor', '.']]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pickle.dump(tagged, open(\"tagged.pkl\", \"wb\"))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:00:52.666092Z",
     "iopub.execute_input": "2023-05-26T14:00:52.666735Z",
     "iopub.status.idle": "2023-05-26T14:00:52.697418Z",
     "shell.execute_reply.started": "2023-05-26T14:00:52.666699Z",
     "shell.execute_reply": "2023-05-26T14:00:52.696210Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tagged = pickle.load(open(\"/kaggle/working/tagged.pkl\", \"rb\"))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:00:52.698925Z",
     "iopub.execute_input": "2023-05-26T14:00:52.699402Z",
     "iopub.status.idle": "2023-05-26T14:00:52.732874Z",
     "shell.execute_reply.started": "2023-05-26T14:00:52.699368Z",
     "shell.execute_reply": "2023-05-26T14:00:52.731537Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "en_list = [en for en, ga in tagged]\n",
    "en_flat = [(word[0].lower(), word[1]) for sent in en_list for word in sent if word[0].lower().isalpha()]\n",
    "word_corpus = dict(en_flat)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:00:52.734449Z",
     "iopub.execute_input": "2023-05-26T14:00:52.734855Z",
     "iopub.status.idle": "2023-05-26T14:00:52.762513Z",
     "shell.execute_reply.started": "2023-05-26T14:00:52.734821Z",
     "shell.execute_reply": "2023-05-26T14:00:52.761535Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "t = GoogleTranslator(source='en', target='ga')\n",
    "\n",
    "idx = nltk.text.ContextIndex([word for sent in [nltk.word_tokenize(contractions.fix(en.lower())) for en in pairs[\"English\"]] for word in sent])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:00:52.764098Z",
     "iopub.execute_input": "2023-05-26T14:00:52.765374Z",
     "iopub.status.idle": "2023-05-26T14:00:53.525901Z",
     "shell.execute_reply.started": "2023-05-26T14:00:52.765336Z",
     "shell.execute_reply": "2023-05-26T14:00:53.524916Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "take random pos-tagged sentence pair from corpus\n",
    "\n",
    "iterate through english sentence, if pos_tag in pos_list:\n",
    "\n",
    "find similar words to chosen word, check for matching pos-tag\n",
    "\n",
    "get irish translation for chosen word and check that it exists in the irish sentence\n",
    "\n",
    "for first word found with matching tag, get translation and replace irish word with it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "r = random.choice(tagged)\n",
    "lr = [[word, tag] for word, tag in r[0]]\n",
    "\n",
    "print(\" \".join([word[0] for word in r[0]]), \"->\", \" \".join(r[1]))\n",
    "\n",
    "pos_list = [\"NN\", \"VBG\", \"NNP\", \"NNS\", \"JJ\", 'PRP', 'PRP$', 'RB']\n",
    "\n",
    "en_new = []\n",
    "for i, (word, tag) in enumerate(lr):\n",
    "    if tag in pos_list:\n",
    "        print(\"in at word\", i, word, tag)\n",
    "        similar_words = idx.similar_words(word) + [word for word, sim in w2v.most_similar(word)]\n",
    "        random.shuffle(similar_words)\n",
    "        print(similar_words)\n",
    "        for similar in similar_words:\n",
    "            lr[i][0] = similar\n",
    "            s = Sentence(\" \".join([word for word, tag in lr]))\n",
    "            print(s)\n",
    "            tagger.predict(s)\n",
    "            new_tag = str(list(s)[i]).split()[-2]\n",
    "            print(tag, new_tag)\n",
    "\n",
    "            if tag == new_tag:\n",
    "                print(w2v.similarity(word, similar))\n",
    "                en_new.append(similar)\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            en_new.append(word)\n",
    "    else:\n",
    "        en_new.append(word)\n",
    "\n",
    "en = \" \".join(en_new)\n",
    "if len(lt.check(en)) > 0:\n",
    "    en = lt.correct(en)\n",
    "    \n",
    "ga = gt.translate(en)\n",
    "\n",
    "print(en, \"->\", ga)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:00:53.527284Z",
     "iopub.execute_input": "2023-05-26T14:00:53.527667Z",
     "iopub.status.idle": "2023-05-26T14:01:01.202618Z",
     "shell.execute_reply.started": "2023-05-26T14:00:53.527626Z",
     "shell.execute_reply": "2023-05-26T14:01:01.201212Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "have you tried it yet ? -> an ndearna tú iarracht é fós ?\nin at word 1 you PRP\n['why', 'me', 'not', 'i', '?', \"n't\", 'we', 'her', 'it', 'she', 'really', 'those', 'who', 'i', 'where', 'do', 'school', 'sure', 'tom', \"'ll\", 'what', 'sleep', 'know', 'ireland', 'want', 'how', 'do', 'they', 'there', 'me']\nSentence[6]: \"have why tried it yet ?\"\nPRP WRB\nSentence[6]: \"have me tried it yet ?\"\nPRP PRP\n0.8585071\nin at word 3 it PRP\n['he', 'peige', 'way', 'everything', 'cáit', 'i', 'colm', 'that', 'everyone', 'english', 'which', 'this', 'irish', 'here', 'tom', 'this', 'so', 'now', 'john', 'what', 'but', '.', 'what', 'she', 'there', 'how', 'just', 'where', 'that', 'life']\nSentence[6]: \"have me tried he yet ?\"\nPRP PRP\n0.7161806\nin at word 4 yet RB\n['exactly', 'why', 'so', 'anything', 'indeed', 'now', 'them', 'that', 'that', 'fact', 'one', 'done', 'her', 'still', 'french', 'but', 'german', 'you', 'though', 'although', 'not', 'tom', 'even', 'him', 'russian', 'english']\nSentence[6]: \"have me tried he exactly ?\"\nRB RB\n0.70882326\nHave me tried he exactly ? -> An ndearna mé iarracht go díreach é?\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "augmented_list = []\n",
    "for r in random.sample(tagged, len(tagged)):\n",
    "    \n",
    "    lr = [[word, tag] for word, tag in r[0]]\n",
    "    en_new = []\n",
    "    \n",
    "    for i, (word, tag) in enumerate(lr):\n",
    "        try:\n",
    "            if tag in pos_list:\n",
    "                similar_words = idx.similar_words(word) + [word for word, sim in w2v.most_similar(word)]\n",
    "                random.shuffle(similar_words)\n",
    "                for similar in similar_words:\n",
    "                    lr[i][0] = similar\n",
    "                    s = Sentence(\" \".join([word for word, tag in lr]))\n",
    "                    tagger.predict(s)\n",
    "                    new_tag = str(list(s)[i]).split()[-2]\n",
    "\n",
    "                    if tag == new_tag:\n",
    "                        en_new.append(similar)\n",
    "                        break\n",
    "\n",
    "                else:\n",
    "                    en_new.append(word)\n",
    "            else:\n",
    "                en_new.append(word)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if en_new:\n",
    "        en = \" \".join(en_new)\n",
    "        if len(lt.check(en)) > 0:\n",
    "            en = lt.correct(en)\n",
    "\n",
    "        ga = gt.translate(en)\n",
    "        augmented_list.append([en, ga])\n",
    "\n",
    "\n",
    "augmented = pd.DataFrame(augmented_list, columns=[\"English\", \"Gaeilge\"]).sample(frac=1).reindex(range(len(augmented_list)))\n",
    "augmented.to_csv(\"data/augmented.csv\")\n",
    "augmented"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-26T14:01:01.206621Z",
     "iopub.execute_input": "2023-05-26T14:01:01.207049Z",
     "iopub.status.idle": "2023-05-26T16:23:40.824987Z",
     "shell.execute_reply.started": "2023-05-26T14:01:01.207016Z",
     "shell.execute_reply": "2023-05-26T16:23:40.822092Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 34\u001B[0m\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lt\u001B[38;5;241m.\u001B[39mcheck(en)) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     32\u001B[0m             en \u001B[38;5;241m=\u001B[39m lt\u001B[38;5;241m.\u001B[39mcorrect(en)\n\u001B[0;32m---> 34\u001B[0m         ga \u001B[38;5;241m=\u001B[39m \u001B[43mgt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranslate\u001B[49m\u001B[43m(\u001B[49m\u001B[43men\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m         augmented_list\u001B[38;5;241m.\u001B[39mappend([en, ga])\n\u001B[1;32m     38\u001B[0m augmented \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(augmented_list, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnglish\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGaeilge\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39msample(frac\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/deep_translator/google.py:67\u001B[0m, in \u001B[0;36mGoogleTranslator.translate\u001B[0;34m(self, text, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpayload_key:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_url_params[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpayload_key] \u001B[38;5;241m=\u001B[39m text\n\u001B[0;32m---> 67\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_base_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_url_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproxies\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m429\u001B[39m:\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TooManyRequests()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:745\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 745\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/response.py:624\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    609\u001B[0m \u001B[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001B[39;00m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    621\u001B[0m \u001B[38;5;124;03m    'content-encoding' header.\u001B[39;00m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunked \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_chunked_reads():\n\u001B[0;32m--> 624\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_chunked(amt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content):\n\u001B[1;32m    625\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m line\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/response.py:828\u001B[0m, in \u001B[0;36mHTTPResponse.read_chunked\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 828\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_chunk_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    830\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/response.py:758\u001B[0m, in \u001B[0;36mHTTPResponse._update_chunk_length\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 758\u001B[0m line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    759\u001B[0m line \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    760\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "nltk.pos_tag(\"What does a Sovietologist study ?\".split())"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(\"What does a Biologist study?\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# load the model\n",
    "tagger = Classifier.load('pos-fast')\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('What does a Biologist study?')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence)\n",
    "\n",
    "str(list(sentence)[0]).split()[-2]"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "str(list(sentence)[0]).split()[-2]"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
